# Hist칩rico de agentes 游뱄


### VERSI칍N 1 (Carpeta Old)

**Nota**: Este prototipo est치 dise침ado para funcionar sin credenciales reales de GLPI, usando datos simulados para demostrar la funcionalidad de generaci칩n de res칰menes con IA.


#### Requisitos de Software

##### 1. Python 3.x
- **Versi칩n recomendada**: Python 3.11 o superior
- **Incluye**: pip para instalar dependencias

##### 2. Ollama (Programa externo)
- **Estado**: Debe estar instalado y ejecut치ndose
- **Modelo requerido**: `phi3:mini`
- **Puerto por defecto**: 11434
- **Comandos necesarios**:
  ```bash
  ollama serve          # Iniciar el servidor
  ollama pull phi3:mini # Descargar el modelo
  ```

##### 3. Dependencias de Python
Archivo `requirements.txt`:
```
python-dotenv==1.0.0
requests==2.31.0
```


#### Orden de Instalaci칩n

1. **Instalar Python 3.x**
   - Descargar desde [python.org](https://python.org)
   - Verificar instalaci칩n: `python --version`

2. **Instalar Ollama**
   - Descargar desde [ollama.ai](https://ollama.ai)
   - Verificar instalaci칩n: `ollama --version`

3. **Descargar modelo de IA**
   ```bash
   ollama pull phi3:mini
   ```

4. **Instalar dependencias de Python**
   ```bash
   pip install -r requirements.txt
   ```

5. **Configurar variables de entorno** (opcional)
   - Crear archivo `.env` con la configuraci칩n de GLPI

6. **Ejecutar el agente**
   ```bash
   python src/agent.py
   ```

   ---
### Versi칩n 2 (Implementaci칩n CrewAI)

Este documento detalla los pasos necesarios para configurar y ejecutar el sistema de agentes inteligentes basado en **CrewAI**. El sistema est치 dise침ado para analizar, clasificar y proponer soluciones a incidencias de soporte t칠cnico.

#### 1. Requisitos Previos

Antes de empezar, aseg칰rate de tener instalado y configurado lo siguiente:

##### Python

Es necesario tener instalado Python en tu sistema con las siguientes dependencias:
    ```bash
    pip install crewai langchain-community python-dotenv requests
    ```
##### Ollama

El motor de los agentes funciona con modelos de lenguaje ejecutados localmente a trav칠s de Ollama.

1.  **Instala Ollama**: Sigue las instrucciones de instalaci칩n desde [ollama.ai](https://ollama.ai).
2.  **Descarga los modelos necesarios**: Este proyecto utiliza modelos espec칤ficos para cada agente con el fin de optimizar el rendimiento. Ejecuta los siguientes comandos para descargarlos:
    ```bash
    ollama pull qwen3
    ollama pull deepseek-coder
    ollama pull deepseek-r1
    ```
3.  **Inicia el servidor de Ollama**: Aseg칰rate de que Ollama se est칠 ejecutando en segundo plano. Por defecto, estar치 disponible en `http://localhost:11434`.

#### 2. Configuraci칩n

Sigue estos pasos para configurar el entorno de ejecuci칩n:

##### Archivo de Incidencia

El script principal (`main_demo.py`) lee la incidencia a analizar desde un fichero de texto. En pr칩ximas veriones esta tarea ser치 realizada por main.py, que leera la incidencia y proporcionar치 el informe directamente en GLPI.

1.  Aseg칰rate de que exista un archivo llamado **`incidencia.txt`** en la carpeta `CrewAi`.
2.  El contenido de este archivo debe ser la descripci칩n de la incidencia que quieres que los agentes analicen. Puedes usar el siguiente ejemplo:
    ```
    T칈TULO: Usuario no puede acceder a la red corporativa desde su port치til

    DESCRIPCI칍N INICIAL:
    El usuario Juan P칠rez (juan.perez@empresa.com) reporta que desde esta ma침ana no puede conectarse a la red corporativa desde su port치til Dell Latitude 5520. El equipo muestra el mensaje "No se puede conectar a esta red" cuando intenta conectarse al WiFi de la oficina. El usuario confirma que la contrase침a es correcta y que otros dispositivos en la misma ubicaci칩n funcionan normalmente.
    ```

##### Herramientas (Tools)

El `buscador_soluciones` utiliza herramientas para diagnosticar problemas.

  * **Wiki.js Tool**: Si deseas conectar el agente a una base de conocimiento de Wiki.js, debes editar el archivo `CrewAi/tools/wikijs_tool.py` y configurar las variables `WIKIJS_URL` y `WIKIJS_API_TOKEN` con tus credenciales.
  * **Ping Tool**: Si deseas que el agente realice un ping a una p치gina, deber치s de indicarlo en el campo habilitado. Por defecto est치 establecida una direcci칩n gen칠rica.

#### 3. Ejecuci칩n

Una vez completados los requisitos y la configuraci칩n, puedes ejecutar el sistema de agentes.

1.  Navega hasta la carpeta `CrewAi` en tu terminal.
2.  Ejecuta el script de demostraci칩n:
    ```bash
    python main_demo.py
    ```

El script iniciar치 el "Crew", que procesar치 la incidencia de manera secuencial a trav칠s de sus agentes. Ver치s en la terminal el razonamiento de cada agente y el resultado final, que ser치 un informe guardado en `informe_soluciones-{timestamp}.md`.

#### 4. Arquitectura de los Agentes

El sistema se compone de tres agentes especializados, cada uno con un modelo de lenguaje recomendado para su tarea espec칤fica (En la documentaci칩n se dispone de un an치lisis detallado):

  * **`analista_sentimiento`**:
      * **Objetivo**: Analizar el estado emocional y la urgencia del cliente.
      * **Modelo recomendado**: **`Qwen3`**, por su capacidad para el an치lisis profundo de matices en el lenguaje.
  * **`clasificador_incidencias`**:
      * **Objetivo**: Etiquetar la incidencia en una categor칤a t칠cnica (Redes, Hardware, etc.).
      * **Modelo recomendado**: **`deepseek-coder`**, por su gran conocimiento de vocabulario t칠cnico.
  * **`buscador_soluciones`**:
      * **Objetivo**: Buscar soluciones y generar un informe detallado.
      * **Modelo recomendado**: **`deepseek-r1`**, por su avanzada capacidad de razonamiento para conectar el problema con las herramientas disponibles.
